Lasso是Least Absolute Shrinkage and Selection Operator的简称，是一种采用了L1正则化（L1-regularization)的线性回归方法，采用了L1正则会使得部分学习到的特征权值为0，从而达到稀疏化和**特征选择**的目的。
 - Ridge Regression的优化目标为：二范数正则项 
 - Lasso的优化目标为：一范数正则项 
   
 ![[Pasted image 20220812162103.png]]

上面的图从几何意义上解释了L1与L2正则化的区别，同时这也解释了L1与L2最大的不同：L1可以带来稀疏的结果，即L1会使得部分参数为零。这样的好处是什么呢？一方面，可以用来选择特征，一方面可以用来降维压缩数据等等。
那么，介绍到这里，L1正则化总是和稀疏挂钩，那么L2正则化呢，L2正则化做了什么事情？其实，和L2正则化挂钩的则是Weight Decay(权值衰减)。下面来简单说一下，考虑一般的优化问题：